---
title: "Confusion Matrix Calculations"
author: "Eric R. Scott"
output: html_notebook
---
This notebook is a heuristic explanation of confusion matrices and Cohen's Kappa coefficient with my simulated data scenarios in mind, followed by analysis of the "control" and "needle in a haystack" data scenarios.  This notebook also outputs figure 3.

**IMPORTANT:** These datasets were generated under R version 3.5.3.  The random number generator in R was updated in version 3.6.0.  For this to be fully reproducible, run with version < 3.6.0 or use `RNGversion("3.5.3")`. 

```{r message=FALSE, warning=FALSE}
library(psych) # for cohen.kappa
library(tidyverse)
library(ropls)
library(here)
library(cowplot)
library(colorspace)
source(here("R", "ropls_helpers.R"))
```


# Confusion Matrixes

To do this, I employ a confusion matrix/kappa coefficient method.  A confusion matrix is just a contingency table with the intended categories of variables on one side, and the actual classification of the variables by some model on the other side.

E.g.:

```{r echo=FALSE}
df <- tribble(~detected.as, ~actual, ~freq,
              "discriminating", "discriminating", 15,
              "discriminating", "uncorrelated", 2,
              "uncorrelated", "uncorrelated", 10,
              "uncorrelated", "discriminating", 3)
xtabs(freq ~ detected.as + actual, data = df) %>% addmargins()
```

We have 15 true positives in the upper left, 10 true negatives in the lower right, and then 2 false positives in the upper right, and 3 false negatives in the lower left.

## Kappa coefficient

Using the confusion matrix, we can calculate Cohen's kappa which summarizes the ability of a model to classify things correctly.

Cohen's kappa is defined as:

$$
\kappa = \frac{ p_o - p_e}{1-p_e}
$$

where $p_o$ is observed proportionate agreement:

$$
p_o = \frac{\text{true positives} + \text{true negatives}}{\text{total}}
$$
In my above example, $p_o = (15+10)/30$ or 0.8333

and $p_e$ is probability of random agreement:

$$
p_e = (p_{(\text{detected discr})}\times p_{(\text{actual discr})}) + (p_{(\text{detected uncorr})} \times p_{(\text{actual uncorr})})
$$
That is, it uses the row and column summs from the contingency table to calculate probabilities.  For example, 17/30 variables were detected as discriminating, so $p_{\text{(detected discr)}} = 0.5666$

```{r}
pe = (17/30 * 18/30) + (12/30 * 13/30)
pe
```

So K = 

```{r}
K = (0.8333333 - pe)/(1-pe)
K
```

# Applying to PLS-DA and PCA-LR

There are multiple ways to decide what a "discriminating" variable is for PCA-LR.  I've decided to choose discriminating variables as those that are significantly correlated with any of the principal components that were significant in the logistic regression part of PCA-LR.

For PLS-DA, I'll use the same criteria as well as VIP > 1.

The name of the variable contains information on whether it was meant to be discriminating or not, so I can then create a confusion matrix and calculate K

# Load data

```{r}
control.pcas <- read_rds(here("data", "models", "control-pcr.rds")) #%>% map("pca")
control.pls <- read_rds(here('data', 'models', 'control-pls.rds'))

needle.pcas <- read_rds(here("data", "models", "needle-pcr.rds")) #%>% map("pca")
needle.pls <- read_rds(here('data', 'models', 'needle-pls.rds'))
```

# Functions

`conf_pcr()` creates a confusion matrix for PCA regression models.  It classifies a variable as being "important" if it is significantly correlated to any of the PCA axes that were significant predictors in the regression.

`conf_pls()` creates a confusion matrics for PLS-DA models.  It classifies a variable as "impotant" if it is significantly correlated to any of the PLS axes.

`conf_pls_vip()` creates a confusion matrix for PLS models produced by `opls()` by extracting VIP scores and assigning variables with VIP > 1 as discrminating.

`calc_kappa()` takes the results of `conf_pcr()` or `conf_pls()` and calculates Cohen's Kappa based on a confusion matrix.

```{r}
conf_pcr <- function(pcr){
  # Separate PCA and regression parts
  pca <- pcr$pca
  reg <- pcr$glm
  
  # Which PCs were significant in the regression?
  pcs <- reg %>% 
    car::Anova() %>% 
    broom::tidy() %>% 
    filter(p.value < 0.05 & term != "(Intercept)") %>% 
    .$term %>%
    syms() #saves as expression for later unquoting with !!!
  
  #get scores and data from PCA part of model
  scores <- pca %>%
    get_scores() %>%
    select(!!!pcs)
  
  data <- pcr$pca@suppLs$xModelMN

  #figure out appropriate cutoff by solving for the r that gives p < 0.05 given n
  n = pca@descriptionMC[1,1] %>% as.numeric()
  t = qt(0.05, n)
  r = sqrt(-(t^2)/(-t^2 - n + 2)) #solved t stat calculation for r
  
  #create confusion matrix
  #variables are detected as discriminating if they have significant correlation with significant PCs
  cor(scores, data) %>%
    t() %>%
    as_tibble(rownames = "Variable") %>% 
    mutate_if(is.numeric, funs(abs(.) > r)) %>% 
    rowwise() %>% 
    mutate(detect_discr = any(!!!pcs),
           is_discr = str_detect(Variable, "D"))
}

```

```{r}
conf_pls <- function(pls){
  #get scores and data
  scores <- pls %>%
    get_scores() %>% 
    select(-y1, -sample) #just keep significant predictive axes columns
  
  #get predictive axis names
  predcomps <- colnames(scores) %>% syms()
  
  data <- pls@suppLs$xModelMN
  
  #figure out appropriate cutoff by solving for the r that gives p < 0.05 given n
  
  n = pls@descriptionMC[1,1] %>% as.numeric()
  t = qt(0.05, n)
  r = sqrt(-(t^2)/(-t^2 - n + 2)) #solved t stat calculation for r
  
  cor(scores, data) %>%
    t() %>%
    as_tibble(rownames = "Variable") %>% 
    mutate_if(is.numeric, list(~abs(.) > r)) %>% 
    rowwise() %>% 
    mutate(detect_discr = any(!!!predcomps),
           is_discr = str_detect(Variable, "D"))
}
```

```{r}
conf_pls_vip <- function(pls.model){
  get_VIP(pls.model) %>%
    mutate(detect_discr = ifelse(VIP > 1, TRUE, FALSE),
           is_discr = ifelse(str_detect(Variable, "D"), TRUE, FALSE))
}
```

```{r}
calc_kappa <- function(confusion_df) {
  confusion_df %>% 
    select(detect_discr, is_discr) %>%
    as.matrix() %>%
    cohen.kappa() %>%
    .$kappa %>% 
    data_frame(kappa = .)
}
```


# Control
## Calculate Cohen's Kappa

**PCA kappas**

```{r message=FALSE, warning=FALSE}
control.pca.k <-
  control.pcas %>%
  map(conf_pcr) %>%
  map_df(calc_kappa, .id = "dataset") %>% 
  rename(pca.k = "kappa")
```


**PLS-DA kappas**

```{r message=FALSE, warning=FALSE}
control.pls.k <-
  control.pls %>% 
  map(conf_pls) %>% 
  map_df(calc_kappa, .id = "dataset") %>% 
  rename(pls.k = "kappa")

control.pls.VIP.k <-
  control.pls %>% 
  map(conf_pls_vip) %>% 
  map_df(calc_kappa, .id = "dataset") %>% 
  rename(pls.VIP.k = "kappa")
```

**Join all kappas**

```{r}
control.k <-
  full_join(control.pca.k, control.pls.k) %>%
  full_join(control.pls.VIP.k) %>% 
  filter(complete.cases(.))
control.k %>% 
  summarise_if(is.numeric, .funs = funs(mean, sd))
```

## Build Plot

```{r}
control.k.plotdata <-
  control.k %>%
  gather(-dataset, key = "Method", value = "Cohen's Kappa") %>% 
  mutate(Method = as.factor(Method) %>%
           fct_recode(`PCA-DA` = "pca.k", `PLS-DA` = "pls.k", `PLS-DA VIP` = "pls.VIP.k"))

control.p <-
  ggplot(control.k.plotdata) +
  geom_density(aes(x = `Cohen's Kappa`, fill = Method, linetype = Method),
               alpha = 0.5, trim = TRUE, adjust = 1.5) +
  scale_fill_discrete_qualitative(palette = "Dark 3") +
  scale_linetype_manual(values = c(1,2,3)) +
  theme_bw() +
  labs(x = "Cohen's Kappa", y = "Frequency", title = '"Control"')
control.p
```

# Needle-in-a-haystack


## Calculate Cohen's Kappa


**PCA kappas**

```{r message=FALSE, warning=FALSE}
needle.pca.k <-
  needle.pcas %>%
  map(conf_pcr) %>%
  map_df(calc_kappa, .id = "dataset") %>% 
  rename(pca.k = "kappa")
```


**PLS-DA kappas**

```{r message=FALSE, warning=FALSE}
needle.pls.k <-
  needle.pls %>%
  map(conf_pls) %>%
  map_df(calc_kappa, .id = "dataset") %>% 
  rename(pls.k = "kappa")

needle.pls.VIP.k <-
  needle.pls %>% 
  map(conf_pls_vip) %>% 
  map_df(calc_kappa, .id = "dataset") %>% 
  rename(pls.VIP.k = "kappa")
```

**Join all kappas**

```{r}
needle.k <-
  full_join(needle.pca.k, needle.pls.k) %>% 
  full_join(needle.pls.VIP.k) %>% 
  filter(complete.cases(.))
needle.k %>% 
  summarize_if(is.numeric, funs(mean, sd))
```

## Build plot

```{r}
needle.k.plotdata <-
  needle.k %>%
  gather(-dataset, key = "Method", value = "Cohen's Kappa") %>% 
  mutate(Method = as.factor(Method) %>% 
           fct_recode(`PCA-DA` = "pca.k", `PLS-DA` = "pls.k", `PLS-DA: VIP > 1` = "pls.VIP.k"))

needle.p <-
  ggplot(needle.k.plotdata) +
  geom_density(aes(x = `Cohen's Kappa`, fill = Method, linetype = Method),
               alpha = 0.5, trim = TRUE, adjust = 1.5) +
  scale_fill_discrete_qualitative(palette = "Dark 3") +
  scale_linetype_manual(values = c(1,2,3)) +
  theme_bw() +
  labs(x = "Cohen's Kappa", y = "Frequency", title = '"Needle in a Haystack"')
needle.p
```

# Plot

```{r}
panels <-
  plot_grid(control.p + theme(legend.position = "none")+ coord_cartesian(xlim = c(-0.5, 1)),
            needle.p + theme(legend.position = "none")+ coord_cartesian(xlim = c(-0.5, 1)),
            nrow = 1,
            ncol = 2,
            labels = glue::glue("({c('a', 'b')})"))
fig2 <-
  plot_grid(panels, get_legend(control.p),
            rel_widths = c(1, 0.15))
fig2
save_plot(here("figs", "kappa.png"), fig2, ncol = 2)
save_plot(here("figs", "figure3.eps"), fig2, ncol = 2)
```

Cohen's Kappa for PCA and PLS-DA important variables under control (a) and needle-in-a-haystack (b) scenarios.




