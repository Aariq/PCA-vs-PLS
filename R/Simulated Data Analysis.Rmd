---
title: "Simulated data analysis"
output: 
  html_notebook: 
    toc: yes
    toc_float: yes
---

# To-Do:

- Write functions for getting kappas to simplify code, move all that to separate .Rmd (perhaps the one called Cohen's Kappas already?)

# Goal
To show that PLS-DA performs better than PCA at figuring out which variables are most responsible for group separation.  I do this using VIP scores from PLS-DA and correlations with PC1 for PCA followed by a calculation of Cohen's Kappa.  For now, I'm only doing this with two of the data scenarios where the variables either contribute to group separation or don't: the positive control, and the needle-in-a-haystack.

For each dataset:

- Do PCA
- Do PLS-DA
- Record how many PLS-DA's fail because even the first component is not significant, but filter out failing models
- Calculate Cohen's Kappa for each method as outlined in "Confusion Matrix.Rmd"
- Plot distributions of Cohen's Kappa
- Possibly do other stuff like:
    + compare p-values from PCA score based t-tests and PLS-DA permutation tests
    + calculate distance between centriods in score plots for PCA and PLS-DA for all datasets
    

# Packages and Functions

```{r message=FALSE, warning=FALSE}
library(here)
library(chemhelper)
library(ropls)
library(psych) #for cohen.kappa()
library(tidyverse)
library(colorspace)
library(cowplot)
```

Create "safe" "partial" version of opls() which returns NULL if it errors and never plots or prints results

```{r}
safe_opls <- safely(partial(opls, printL = FALSE, plotL = FALSE), otherwise = NULL)
```

# Load Data

```{r}
null <- read_rds(here("data", "null.rds"))
needle <- read_rds(here("data", "needle.rds"))
red_herring <- read_rds(here("data", "red herring.rds"))
control <- read_rds(here("data", "control.rds"))
```


# Run Analyses

For each scenario, run PCA and PLS-DA on all datasets.  Record errors, and calculate summary statistics on the models that are successfullly built

## Null

### Null PCAs

```{r}
# map the pca function to all datasets
null.pcas.try <-
  null %>% 
  map(~safe_opls(select(., -group)))

# Get just the successful models
null.pcas <-
  null.pcas.try %>%
  map("result") %>% #get only results
  discard(is.null) #get rid of any with NULL results (and therefore an error)
```

Any errors?

```{r}
length(null.pcas.try) - length(null.pcas)
```

### Null PLSs

```{r}
null.pls.try <-
  null %>% 
  map(~ safe_opls(select(., -group), .$group)) #map the opls

# get just succesful models
null.pls <-
  null.pls.try %>% 
  map("result") %>% 
  discard(is.null)
```

Any errors?

```{r}
length(null.pls.try) - length(null.pls)
```

75/100 models failed.  Why?

```{r}
null.pls.try %>% 
  map("error") %>%
  unique()
```

They all failed because the first predictive component already wasn't significant.

## Control

### Control PCAs

```{r}
# map the pca function to all datasets
control.pcas.try <-
  map(control,
      ~safe_opls(select(., -group)))

control.pcas <-
  control.pcas.try %>%
  map("result") %>% 
  discard(is.null)
```

How many errors? 

```{r}
length(control.pcas.try) - length(control.pcas)

#What was the error?
control.pcas.try %>% 
  map("error") %>% 
  unique()
```

One failed model due to convergence problems

### Control PLS-DAs

```{r}
control.pls.try <-
  map(control,
      ~ safe_opls(select(., -group), .$group))

control.pls <-
  control.pls.try %>% 
  map("result") %>% 
  discard(is.null)
```

How many failed models?

```{r}
length(control.pls.try) - length(control.pls)
```

zero failed models

## Needle in a haystack

### Needle PCAs

```{r}
needle.pcas.try <-
  map(needle,
      ~safe_opls(select(., -group)))

needle.pcas <-
  needle.pcas.try %>% 
  map("result") %>% 
  discard(is.null)
```

Any errors?

```{r}
length(needle.pcas.try) - length(needle.pcas)
```

zero failed models 

### Needle PLS-DAs

```{r}
needle.pls.try <-
  map(needle,
      ~ safe_opls(select(., -group), .$group))

needle.pls <-
  needle.pls.try %>% 
  map("result") %>% 
  discard(is.null)
```

Any errors?

```{r}
length(needle.pls.try) - length(needle.pls)
```

zero errors

## Red Herring (might not use this one)

### Red Herrign PCAs

```{r}
herring.pcas.try <-
  map(red_herring,
      ~safe_opls(select(., -group)))

herring.pcas <-
  herring.pcas.try %>% 
  map("result") %>% 
  discard(is.null)
```

Any errors?

```{r}
length(herring.pcas.try) - length(herring.pcas)
```

Zero errors

### Red Herring PLS-DAs

```{r}
herring.pls.try <-
  map(red_herring,
      ~ safe_opls(select(., -group), .$group))

herring.pls <-
  herring.pls.try %>% 
  map("result") %>% 
  discard(is.null)
```

Any errors?

```{r}
length(herring.pls.try) - length(herring.pls)
```

Zero errors


# Get Summary Stats
## Map R2 and Q2 extractor

**Control**

```{r}
control.pls %>%
  map(~get_modelinfo(.)) %>%
  map_dfr(~list(Q2 = pluck(., 2, "Q2(cum)"),
                R2 = pluck(., 2, "R2Y(cum)")),
          .id = "dataset") %>% 
  summarize_if(is.numeric, funs(mean, sd))
```

**Null**

```{r}
null.pls %>%
  map(~get_modelinfo(.)) %>%
  map_dfr(~list(Q2 = pluck(., 2, "Q2(cum)"),
                R2 = pluck(., 2, "R2Y(cum)")),
          .id = "dataset") %>% 
  summarize_if(is.numeric, funs(mean, sd))
```

**Needle-in-a-haystack**

```{r}
needle.pls %>%
  map(~get_modelinfo(.)) %>%
  map_dfr(~list(Q2 = pluck(., 2, "Q2(cum)"),
                R2 = pluck(., 2, "R2Y(cum)")),
          .id = "dataset") %>% 
  summarize_if(is.numeric, funs(mean, sd))
```

**Red Herring**

```{r}
herring.pls %>%
  map(~get_modelinfo(.)) %>%
  map_dfr(~list(Q2 = pluck(., 2, "Q2(cum)"),
                R2 = pluck(., 2, "R2Y(cum)")),
          .id = "dataset") %>% 
  summarize_if(is.numeric, funs(mean, sd))
```







# Kappa Coeficient

For the control and needle scenarios, calculate kappa coefficient on confusion matrices built on ability to identify discriminating variables.
## Control
### Calculate Cohen's Kappa

- For PCA, I'm defining an "important" variable as one with a correlation to PC1 > 0.5 or  < -0.5
- For PLS, an "important" variable is one with a VIP score > 1

**PCA kappas**

```{r message=FALSE, warning=FALSE}
# Get correlations
control.cors <-
  map2(.x = control.pcas,
       #filter .y by getting rid of models that didn't run
       .y = control[!control.pcas.failed], 
       #correlation between axis scores and data
       ~ cor(get_scores(.x)[2:3], select(.y, -group)) %>% 
         t() %>% 
         as_data_frame(rownames = "Variable")) %>% 
  # calculate distance from center in correlation units for each variable
  map(~ rowwise(.) %>% 
        mutate(distance = sqrt(sum((c(p1, p2) - c(0, 0))^2))) %>% 
        # if corr distance > 0.5, then its "important" variable
        mutate(detect_discr = ifelse(distance > 0.5, TRUE, FALSE),
               #detect_discr = ifelse(abs(p1) > 0.5, TRUE, FALSE),
               is_discr = ifelse(str_detect(Variable, "D"), TRUE, FALSE))
        )
sample(control.cors, 2)
# calculate kappa
control.pca.k <- 
  map_dfr(control.cors,
      ~ select(., detect_discr, is_discr) %>%
        as.matrix() %>%
        cohen.kappa() %>%
        .$kappa %>%
        data_frame(pca.k = .),
      .id = "dataset")
```


**PLS-DA kappas**

```{r message=FALSE, warning=FALSE}
# Get VIP scores
control.vips <-
  map(control.pls,
      ~ get_VIP(.) %>% 
        mutate(detect_discr = ifelse(VIP > 1, TRUE, FALSE),
               is_discr = ifelse(str_detect(Variable, "D"), TRUE, FALSE)))

control.pls.k <- 
  map_dfr(control.vips,
      ~ select(., detect_discr, is_discr) %>%
        as.matrix() %>%
        cohen.kappa() %>%
        .$kappa %>%
        data_frame(pls.k = .),
      .id = "dataset")
```

**Join all kappas**

```{r}
control.k <- full_join(control.pca.k, control.pls.k) %>% filter(complete.cases(.))
```

### Build Plot

```{r}
control.k.plotdata <-
  control.k %>%
  gather(-dataset, key = "Method", value = "Cohen's Kappa") %>% 
  mutate(Method = as.factor(Method) %>% fct_recode(PCA = "pca.k", `PLS-DA` = "pls.k"))

control.p <-
  ggplot(control.k.plotdata) +
  geom_histogram(aes(x = `Cohen's Kappa`, fill = Method),
                 position = "identity", alpha = 0.8,
                 binwidth = 0.1) +
  # geom_density(aes(x = `Cohen's Kappa`, fill = Method), alpha = 0.7, trim = TRUE) +
  scale_fill_discrete_qualitative(palette = "Dark 3") +
  theme_bw() +
  labs(x = "Cohen's Kappa", y = "Frequency")
control.p
```

# Needle-in-a-haystack



## Calculate Cohen's Kappa

- For PCA, I'm defining an "important" variable as one with a correlation to PC1 > 0.5 or  < -0.5
- For PLS, an "important" variable is one with a VIP score > 1

**PCA kappas**

```{r message=FALSE, warning=FALSE}
# Get correlations
needle.cors <-
  map2(.x = needle.pcas,
       #filter .y by getting rid of models that didn't run
       .y = needle[!needle.pcas.failed], 
       #correlation between axis scores and data
       ~ cor(get_scores(.x)[2:3], select(.y, -group)) %>% 
         t() %>% 
         as_data_frame(rownames = "Variable")) %>% 
  # calculate distance from center in correlation units for each variable
  map(~ rowwise(.) %>% 
        mutate(distance = sqrt(sum((c(p1, p2) - c(0, 0))^2))) %>% 
        # if corr distance > 0.5, then its "important" variable
        mutate(detect_discr = ifelse(distance > 0.5, TRUE, FALSE),
               # detect_discr = ifelse(abs(p1) > 0.5, TRUE, FALSE),
               is_discr = ifelse(str_detect(Variable, "D"), TRUE, FALSE))
        )

# calculate kappa
needle.pca.k <- 
  map_dfr(needle.cors,
      ~ select(., detect_discr, is_discr) %>%
        as.matrix() %>%
        cohen.kappa() %>%
        .$kappa %>%
        data_frame(pca.k = .),
      .id = "dataset")
```


**PLS-DA kappas**

```{r message=FALSE, warning=FALSE}
# Get VIP scores
needle.vips <-
  map(needle.pls,
      ~ get_VIP(.) %>% 
        mutate(detect_discr = ifelse(VIP > 1, TRUE, FALSE),
               is_discr = ifelse(str_detect(Variable, "D"), TRUE, FALSE)))

needle.pls.k <- 
  map_dfr(needle.vips,
      ~ select(., detect_discr, is_discr) %>%
        as.matrix() %>%
        cohen.kappa() %>%
        .$kappa %>%
        data_frame(pls.k = .),
      .id = "dataset")
```

**Join all kappas**

```{r}
needle.k <- full_join(needle.pca.k, needle.pls.k)
```

### Build plot

```{r}
needle.k.plotdata <-
  needle.k %>%
  gather(-dataset, key = "Method", value = "Cohen's Kappa") %>% 
  mutate(Method = as.factor(Method) %>% fct_recode(PCA = "pca.k", `PLS-DA` = "pls.k"))

needle.p <-
  ggplot(needle.k.plotdata) +
  geom_histogram(aes(x = `Cohen's Kappa`, fill = Method),
                 position = "identity", alpha = 0.8,
                 binwidth = 0.1) +
  # geom_density(aes(x = `Cohen's Kappa`, fill = Method), alpha = 0.7, trim = TRUE) +
  scale_fill_discrete_qualitative(palette = "Dark 3") +
  theme_bw() +
  labs(x = "Cohen's Kappa", y = "Frequency")
needle.p
```

# Plot

```{r}
panels <-
  plot_grid(control.p + theme(legend.position = "none")+ coord_cartesian(xlim = c(-0.5, 1)),
            needle.p + theme(legend.position = "none")+ coord_cartesian(xlim = c(-0.5, 1)),
            nrow = 1,
            ncol = 2,
            labels = "auto")
fig2 <-
  plot_grid(panels, get_legend(control.p),
            rel_widths = c(1, 0.15))
fig2
save_plot(here("figs", "fig2.png"), fig2, ncol = 2)
```

Cohen's Kappa for PCA and PLS-DA important variables under control (a) and needle-in-a-haystack (b) scenarios.

# PLS statistics for all scenarios
I want to get $R^2$ and $Q^2_y$ with standard deviations for all scenarios.

I already did control and needle. That leaves null and red herring.



zero models failed



