---
title: "What's the deal with PCR?"
output: html_notebook
---

Goal:

- ~~figure out what pcr() function does~~
- ~~best way to select # of components to include in regression~~
- how to get RMSEP from pcr
- how best to map this to opls()-created pca models
- Do a regression on a factor or can you get RMSEP from a t-test?

```{r}
library(holodeck)
library(ropls)
library(tidyverse)
library(iheatmapr)
```

# Make a test dataset

I'm going to convert the group factor to numeric to simplify the process of figuring out how to do cross validation. Elizabeth and I confirmed that PLS-DA is just PLS with a dummy variable for the groups.

```{r}
set.seed(420)
df <- sim_cat(N = 30, n_groups = 2) %>% 
  sim_covar(p = 5, var = 1, cov = 0.5, name = "cov") %>% 
  sim_covar(p = 5, var = 1, cov = 0.5, name = "cov2") %>% 
  # sim_covar(p = 5, var = 1, cov = 0, name = "noise") %>% 
  group_by(group) %>% 
  sim_discr(p = 5, var = 1, cov = 0.1, group_means = c(-1, 1), name = "discr") %>%
  ungroup() #%>% 
  # mutate(group = as.numeric(as.factor(group)))

X = df %>% select(-group)
Y = df$group
```

## Visualize covariance

```{r}
# df %>% 
#   select(-group) %>% 
#   cov() %>% 
#   iheatmap()
```


# Do PLSR

```{r}
plsda <- opls(select(df, -group), df$group, plotL = FALSE)
```


# Do PCA + Regression

```{r}
pca <- opls(select(df, -group), plotL = FALSE)
pca_mod <- pca.null <- opls(select(null$null_df_1, -group), plotL = FALSE)
```




## Get scores

```{r}
scores <- get_scores(pca)
df.aug <-
  df %>% 
  add_column(p1 = scores$p1, p2 = scores$p2)

df.aug %>% select(group, p1, p2)

scores.null <- get_scores(pca.null)
null.aug <- 
  null$null_df_1 %>% add_column(p1 = scores.null$p1,
                                p2 = scores.null$p2,
                                p3 = scores.null$p3)
```

## Regression

```{r}
m <- glm(as.numeric(group) ~ p1 + p2, family = gaussian, data = df.aug)
summary(m)
car::Anova(m)

m <- glm(as.numeric(as.factor(group)) ~ p1 + p2 + p3, family = gaussian, data = null.aug)
```


# Cross-validation

Goal: match CV that `opls()` does with PLS-DA models

0. Read worley and powers utilites paper
1. subset data
2. run PCA on analysis(data)
3. Use resulting loadings to predict PC scores on assessment(data)
4. do glm() on analysis(data)
5. use glm() to predict group membership for assessment(data)
6. calculate RMSEP

## 1. Create splits

Using `rsample` package

```{r}
library(rsample)
df.cv <- vfold_cv(df, 7)
null.cv <- vfold_cv(null$null_df_1, 7)
null.cv$splits[[1]] %>% analysis()
null.cv$splits[[1]] %>% assessment()

```

## 2-5. CV function

First, a predict function to calculate scores from loadings and data

```{r}
# .newdata = sim_cat(N = 6, n_groups = 2) %>% 
#   sim_covar(p = 5, var = 1, cov = 0.5, name = "cov") %>% 
#   sim_covar(p = 5, var = 1, cov = 0.5, name = "cov2") %>% 
#   group_by(group) %>% 
#   sim_discr(p = 5, var = 1, cov = 0.1, group_means = c(-1, 1), name = "discr") %>% 
#   ungroup() %>% 
#   mutate(group = as.numeric(as.factor(group))) %>% 
#   select(-group) %>% 
#   mutate_all(~scale(.))
# 
# pca_mod = pca
```


```{r}
mypredict <- function(pca_mod, .newdata, .scale = TRUE) {
  #get loadings
  load <-
    get_loadings(pca_mod) %>%
    gather(-Variable, key = axis, value = loading) %>%
    spread(Variable, loading) %>% 
    select(axis, colnames(.newdata))
  
  #scale newdata
  if(.scale){
    .newdata <- .newdata %>% mutate_all(~scale(.))
  }
  
  #check that columns are the same
  stopifnot(identical(colnames(.newdata), colnames(load %>% select(-axis))))
  
  #calc scores from loadings
  #clunky, but works
  pred.scores <-
    load %>% 
    group_by(axis) %>% 
    group_map(~{
      map2_dfc(.x = .newdata, .y = ., ~.x*.y) %>% rowSums(.) %>% as_tibble()
    }) %>% 
    mutate(sample = paste0("s", 1:nrow(.newdata))) %>% 
    spread(axis, value)
  
  return(pred.scores)
}
```

**Apply this to original data to check if it works!!!**

```{r}
mypredict(pca, df %>% select(-group)) %>% arrange((sample))
get_scores(pca) %>% arrange(sample)
```



This function should calculate RMSEP for a single split

```{r}
#model formula
mod_form <- as.formula(group ~ p1 + p2)

#test split
split <- df.cv$splits[[1]]

pca_RMSEP <- function(split, X_vars, Y_var) {
  #do pca on analysis(data)
  
  X <- enquo(X_vars)
  Y <- enquo(Y_var)
  # Do PCA on X
  pca <- opls(select(analysis(split), !!X), plotL = FALSE, printL = FALSE)
  
  # Get scores and bind with Y
  scores <-
    get_scores(pca) %>% 
    add_column(!!Y := analysis(split)[[quo_name(Y)]])
  
  #predict pc axis scores on assessment data
  scores.pred <- mypredict(pca, assessment(split) %>% select(!!X))
  
  # Make formula
  npcs <- pca@summaryDF$pre
  pcs <- glue("p{1:npcs}")
  mod_form <- as.formula(glue("{quo_name(Y)} ~ {glue_collapse(pcs, sep = '+')}"))
  
  #do glm on analysis data
  m <- glm(mod_form, family = gaussian, data = scores)
  
  #use glm to predict `group` for newdata
  scores.pred %>%
    mutate(group.pred = predict(m, newdata = scores.pred)) %>%
    add_column(group.actual = assessment(split)[[quo_name(Y)]]) %>%
    mutate(sq_err = (group.actual - group.pred)^2) %>%
    summarize(RMSEP = sqrt(mean(sq_err))) %>%
    as.numeric()
}

```

$$
RMSEE = \sqrt{\frac{1}{n}\times \sum(A_i-P_i)^2}
$$

```{r}
example <- pca_RMSEP(df.cv$splits[[1]], X_vars = -group, Y_var = group)
analysis(df.cv$splits[[1]])
```

#6. apply that function to all the splits and get mean RMSEP

```{r}
df.cv %>%
  mutate(RMSEP = map_dbl(splits, RMSEP)) %>% 
  summarize(RMSEP = mean(RMSEP))
```


# Q^2^

$$
Q^2 = (1-PRESS/SS)
$$

$$
PRESS = \sum_i\sum_m(Y_{im} - \hat{Y}_{im})^2
$$
Or the squared differences between observed and predicted values when observations were kept out.  SS is the residual sum of squares.  When Q^2^ is computed for PLS-DA, its the product of the Q^2^ for each component.  So, I'm not sure that it's really comparable if I calculate this for PCA-DA

```{r}
test.split <- df.cv$splits[[1]]
assessment(test.split)
analysis(test.split)
```

do PCA

```{r}
# Do PCA on X
pca <- opls(select(analysis(test.split), -group), plotL = FALSE, printL = FALSE)

# Get scores and bind with Y
scores <- get_scores(pca) %>% 
  add_column(group = analysis(test.split)$group)

#predict pc axis scores on assessment data
scores.pred <- mypredict(pca, assessment(test.split) %>% select(-group))
  
```

do regression

```{r}
  #do glm on analysis data
m <- lm(as.numeric(as.factor(group)) ~ p1 + p2, data = scores)
m %>% broom::augment() %>% 
  mutate(sqdev = (.fitted - .resid)^2) %>% 
  summarize(SS = sum(sqdev))


scores.pred %>%
    mutate(group.pred = predict(m, newdata = scores.pred)) %>%
    add_column(group.actual = assessment(split)[["group"]]) %>%
    mutate(sq_err = (group.actual - group.pred)^2) %>%
    summarize(RMSEP = sqrt(mean(sq_err))) %>%
    as.numeric()

broom::glance(m)
```


Is the SS from the full model?  I think maybe?




```{r}
View(plsda)
```


